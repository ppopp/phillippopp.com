<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
        <!-- TemplateBeginEditable name="doctitle" -->
        <title>Phillip Popp</title>
        <!-- TemplateEndEditable -->
        <!-- TemplateBeginEditable name="head" -->
        <!-- TemplateEndEditable -->
        <link href="../../../main/main.css" rel="stylesheet" type="text/css" />
        </script>
    </head>
    
    <body class="twoCol">    
        <div id="container">
          <p class="nav_link"><a href="../../../main/index.html">Main</a></p>
          <p class="nav_link" style="text-decoration:line-through">Sound</p>
          <p class="nav_link" ><a href="../../../main/the_interweb/index.html">The Interweb</a></p>
          <p class="nav_link" style="text-decoration:line-through">Code</p>
          <p class="nav_link"><a href="../../../main/publications/index.html">Publications</a></p>
          <p class="nav_link" style="text-decoration:line-through">Resume</p>
                <p class="nav_link"><a href="../../../main/contact/index.html">Contact</a></p>
            <br class="clearfloat" />
          <div id="mainContent">
            <!-- TemplateBeginEditable name="main_content" -->
                <h1>Sound Brush</h1>
                <p>Several methods exist for manipulating spectral models 
	either by applying transformations via higher level features or by 
	providing in-depth offline editing capabilities. In contrast, our system 
	aims for direct, full, intuitive, real-time control without exposing any 
	spectral model features to the user. The system extends upon previous 
	machine learning work in gesture-synthesis mapping by applying it to 
	spectral models; these are a unique and interesting use case in that they 
	are capable of reproducing real world recordings, due to their relatively 
	high data rate and complex, inter- twined and synergetic structure. To 
	achieve a direct and intuitive control of a spectral model, a method to 
	extract an individualized mapping between Wacom Pen parameters and 
	Spectral Model Synthesis frames is described and implemented as a 
	standalone application. The method works by capturing tablet parameters as 
	the user pantomimes to synthesized spectral model. A transformation from 
	Wacom Pen parameters to gestures is obtained by extracting features from 
	the pen and then transforming those features using Principal Component 
	Analysis. Then a linear model maps between gestures and higher level 
	features of the spectral model frames while a k-nearest neighbor algorithm 
	maps between gestures and normalized spectral model frames.</p>
                <h2>Download</h2>
				<p><a href="soundbrush.app.zip">sound brush</a> max osx 10.6</p>
				<h2>Paper</h2>
				<p><a href"../../publications/nime_2011_phillip_popp.pdf">Intuitive Real-Time Control of Spectral Model Synthesis</a></p>
            <!-- TemplateEndEditable -->
		  </div>
            <br class="clearfloat" />
        <p class="footer">Popp.Phillip <em>at</em> gmail <em>dot</em> com </p>
        </div>
    </body>
</html>
